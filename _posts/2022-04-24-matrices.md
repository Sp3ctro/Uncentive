---
layout: post
title: "Matrices"
author: "Uncentive"
categories: post
tags: [Maths]
---

In mathematics, a matrix (plural: matrices) is a rectangular array or table of numbers, symbols, or expressions, arranged in rows and columns, which is used to represent a mathematical object or a property of such an object. The dimensions of a matrix are denoted as $r \times c$, with the number of rows always being expressed first. Several operations can be performed on matrices; we'll cover those in a future post.

## Notational Conventions
Some authors try to use notation that helps readers distinguish between matrices, vectors and scalars (numbers). Greek letters ($\alpha, \beta$...) might be used for numbers, lower-case letters ($a, x, f$...) might be used for vectors, and capital letters ($A, F$...) for matrices. Matrices are also often denoted in bold font ($\bf{G}$ rather than $G$), and vectors are often written with an arrow above the letter (such as  \overrightarrow{v}).

## Useful Identities
Transpose of a product $(AB)^T = B^T A^T$

Transpose of a sum $(A+B)^T = A^T + B^T$

Inverse of a product: $(AB)^{-1} = B^-1 A^-1$ provided A and B are square and invertible.

Products of powers: $A^kA^l = A^{k+l}$ for (k, l >= 1 in general, and for all k, l if A is invertible)

## Types of Matrices
There are many types of matrix, such as...

### Symmetric Matrix
A symmetric matrix is defined to be one for which $$A' = A$$, specifically that $a_{ij} = a_{ji} for i \neq j$. This property can only hold for square matrices $(m = n)$, since otherwise **A'** and **A** won't be of the same order (meaning not of the same size or shape).

### Identity Matrix
Also known as the unit matrix, this is a matrix of the order $(n \times n)$ which has zeros in all places except for the diagonals which are 1s.

$$\bf{I}_{3 \times 3} = \begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}$$

In the case of the identity matrix, $IA = AI = A$

### Diagonal Matrix
A diagonal matrix is like the identity matrix, in that only the diagonal of the matrix is populated with values - everything else is 0. The identity matrix is a diagonal matrix, but a diagonal matrix might not necessarily be the identity matrix.

### Idempotent Matrix
An idempotent matrix is a matrix which, when multiplied by itself, yields itself. If matrix **A** is a square, symmetric matrix such that $A' = A$ then it will be idempotent if $A = A^2 = A^3 = ...$

### Null Matrix
The null matrix is simply a matrix of the order $(m \times n)$ which is populated entirely be zeros.

### Hessian Matrix
A Hessian Matrix is a matrix of second order derivatives of s scalar valued function. The hessian matrix of a multivariate function $f(x,y,z)$ organizes all second order partial derivatives into a matrix...

$$\mathbf H_f=\begin{bmatrix}
  \dfrac{\partial^2 f}{\partial x_1^2} & \dfrac{\partial^2 f}{\partial x_1\,\partial x_2} & \cdots & \dfrac{\partial^2 f}{\partial x_1\,\partial x_n} \\[2.2ex]
  \dfrac{\partial^2 f}{\partial x_2\,\partial x_1} & \dfrac{\partial^2 f}{\partial x_2^2} & \cdots & \dfrac{\partial^2 f}{\partial x_2\,\partial x_n} \\[2.2ex]
  \vdots & \vdots & \ddots & \vdots \\[2.2ex]
  \dfrac{\partial^2 f}{\partial x_n\,\partial x_1} & \dfrac{\partial^2 f}{\partial x_n\,\partial x_2} & \cdots & \dfrac{\partial^2 f}{\partial x_n^2}
\end{bmatrix}$$

### Jacobian Matrix
In vector calculus, the Jacobian Matrix of a vector function in several variables is the matrix of all its first order partial derivatives. When this matrix is square, its determinant is the Jacobian determinant.

### Invertible Matrix
In [linear algebra](https://en.wikipedia.org/wiki/Linear_algebra "Linear algebra"), an n-by-n [square matrix](https://en.wikipedia.org/wiki/Square_matrix "Square matrix") **A** is called **invertible** (also **nonsingular** or **nondegenerate**), if there exists an _n_-by-_n_ square matrix **B** such that $AB = BA = I_n$, where $I_n$ denotes the n-by-n  [identity matrix](https://en.wikipedia.org/wiki/Identity_matrix "Identity matrix") and the multiplication used is ordinary [matrix multiplication](https://en.wikipedia.org/wiki/Matrix_multiplication). If this is the case, then the matrix **B** is uniquely determined by **A**, and is called the (multiplicative) _**inverse**_ of **A**, denoted by **A**âˆ’1.

**Matrix inversion** is the process of finding the matrix **B** that satisfies the prior equation for a given invertible matrix **A**.

If the determinant of the matrix is nonzero then the matrix is Invertible.

### Singular Matrix
A Singular Matrix is a matrix which does not have an inverse version of itself. In other words, a Singular Matrix is one which cannot be inverted.

### Positive Semi-Definite Matrix
A Positive Semi-Definite Matrix, otherwise known as a Hermitian matrix, is a type of arithmetic [Matrices](app://obsidian.md/Matrices), and whose [Eigenvalues](app://obsidian.md/Eigenvalues) are nonnegative. A symmetric matrix M is positive semi-definite if the real number zMzT is positive for every nonzero real number vector **z**.
